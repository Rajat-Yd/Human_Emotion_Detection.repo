{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPwXXHjh/VImqsA1+4Ximsm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf### models\n",
        "import numpy as np### math computations\n",
        "import matplotlib.pyplot as plt### plotting bar chart\n",
        "import sklearn### machine learning library\n",
        "import cv2## image processing\n",
        "from sklearn.metrics import confusion_matrix, roc_curve### metrics\n",
        "import seaborn as sns### visualizations\n",
        "import datetime\n",
        "import pathlib\n",
        "import io\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_probability as tfp\n",
        "import matplotlib.cm as cm\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import (GlobalAveragePooling2D, Activation, MaxPooling2D, Add, Conv2D, MaxPool2D, Dense,\n",
        "                                     Flatten, InputLayer, BatchNormalization, Input, Embedding, Permute,\n",
        "                                     Dropout, RandomFlip, RandomRotation, LayerNormalization, MultiHeadAttention,\n",
        "                                     RandomContrast, Rescaling, Resizing, Reshape)\n",
        "from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import (Callback, CSVLogger, EarlyStopping, LearningRateScheduler,\n",
        "                                        ModelCheckpoint, ReduceLROnPlateau)\n",
        "from tensorflow.keras.regularizers  import L2, L1\n",
        "from tensorflow.train import BytesList, FloatList, Int64List\n",
        "from tensorflow.train import Example, Features, Feature\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "wXzyUgsp7RYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless"
      ],
      "metadata": {
        "id": "cxa2GjgxwQgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Dataset Downloading</h1>"
      ],
      "metadata": {
        "id": "azLG64fn5I6k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60YfcTOz2o7a"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "y2Nd8S8R4pJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 /content/kaggle.json"
      ],
      "metadata": {
        "id": "Rlnecu1r43kY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d muhammadhananasghar/human-emotions-datasethes"
      ],
      "metadata": {
        "id": "WTzP_ebz5CpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/human-emotions-datasethes.zip\" -d \"/content/dataset\""
      ],
      "metadata": {
        "id": "93wYidPZ5Xc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_directory = \"/content/dataset/Emotions Dataset/Emotions Dataset/train\"\n",
        "val_directory =\"/content/dataset/Emotions Dataset/Emotions Dataset/test\"\n",
        "CLASS_NAMES = [\"angry\", \"happy\", \"sad\"]"
      ],
      "metadata": {
        "id": "gKXCVq6m6qzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIGURATION = {\n",
        "    \"BATCH_SIZE\": 32,\n",
        "    \"IM_SIZE\": 224,\n",
        "    \"LEARNING_RATE\": 1e-3,\n",
        "    \"N_EPOCHS\": 40,\n",
        "    \"DROPOUT_RATE\": 0.5,\n",
        "    \"REGULARIZATION_RATE\": 0.0,\n",
        "    \"N_FILTERS\": 6,\n",
        "    \"KERNEL_SIZE\": 3,\n",
        "    \"N_STRIDES\": 1,\n",
        "    \"POOL_SIZE\": 2,\n",
        "    \"N_DENSE_1\": 1024,\n",
        "    \"N_DENSE_2\": 128,\n",
        "    \"NUM_CLASSES\": 3,\n",
        "    \"PATCH_SIZE\": 16,\n",
        "    \"PROJ_DIM\": 768,\n",
        "    \"CLASS_NAMES\": [\"angry\", \"happy\", \"sad\"],\n",
        "}"
      ],
      "metadata": {
        "id": "rc4BTR6jyexE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Dataset Loading</h1>"
      ],
      "metadata": {
        "id": "7n5ELGAC6LXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_directory,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    class_names=CLASS_NAMES,\n",
        "    color_mode='rgb',\n",
        "    batch_size=CONFIGURATION[\"BATCH_SIZE\"],\n",
        "    image_size=(CONFIGURATION[\"IM_SIZE\"], CONFIGURATION[\"IM_SIZE\"]),\n",
        "    shuffle=True,\n",
        "    seed=99,\n",
        ")"
      ],
      "metadata": {
        "id": "wUPeS2Sk5ogP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    val_directory,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    class_names=CLASS_NAMES,\n",
        "    color_mode='rgb',\n",
        "    batch_size=CONFIGURATION[\"BATCH_SIZE\"],\n",
        "    image_size=(CONFIGURATION[\"IM_SIZE\"], CONFIGURATION[\"IM_SIZE\"]),\n",
        "    shuffle=True,\n",
        "    seed=99,\n",
        ")"
      ],
      "metadata": {
        "id": "t2AUD_IRmcUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in val_dataset.take(1):\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "hzlMgr2Nm7nN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Data Visualization</h1>"
      ],
      "metadata": {
        "id": "mCYiAwqToo7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "\n",
        "for images, labels in train_dataset.take(1):\n",
        "  for i in range(10):\n",
        "    ax = plt.subplot(4,4, i+1)\n",
        "    plt.imshow(images[i]/255.)\n",
        "    plt.title(CLASS_NAMES[tf.argmax(labels[i], axis = 0).numpy()])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "MV3PZO0ZoCh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>DATA PREPARATION</h1>"
      ],
      "metadata": {
        "id": "xGqEMazOtyFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset = (\n",
        "    train_dataset\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")"
      ],
      "metadata": {
        "id": "CFUIvV-3phHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataset = (\n",
        "    val_dataset\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")"
      ],
      "metadata": {
        "id": "XVpYaAytu9I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resize_rescale_layers = tf.keras.Sequential(\n",
        "    [\n",
        "        Resizing(CONFIGURATION[\"IM_SIZE\"], CONFIGURATION[\"IM_SIZE\"]),\n",
        "        Rescaling(1./255),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "P8dFRY3PvHHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Data Augmentation</h1>"
      ],
      "metadata": {
        "id": "EXcx0u215hjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_directory,\n",
        "    target_size=(CONFIGURATION[\"IM_SIZE\"], CONFIGURATION[\"IM_SIZE\"]),\n",
        "    batch_size=CONFIGURATION[\"BATCH_SIZE\"],\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    train_directory,\n",
        "    target_size=(CONFIGURATION[\"IM_SIZE\"], CONFIGURATION[\"IM_SIZE\"]),\n",
        "    batch_size=CONFIGURATION[\"BATCH_SIZE\"],\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "id": "IvMAPzBa5qE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>MODELING</h1>"
      ],
      "metadata": {
        "id": "gr7lDV-qwzCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model = tf.keras.Sequential(\n",
        "    [\n",
        "    InputLayer(input_shape = (None, None, 3), ),\n",
        "\n",
        "    resize_rescale_layers,\n",
        "\n",
        "    Conv2D(filters = CONFIGURATION[\"N_FILTERS\"] , kernel_size = CONFIGURATION[\"KERNEL_SIZE\"], strides = CONFIGURATION[\"N_STRIDES\"] , padding='valid',\n",
        "          activation = 'relu',kernel_regularizer = L2(CONFIGURATION[\"REGULARIZATION_RATE\"])),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D (pool_size = CONFIGURATION[\"POOL_SIZE\"], strides= CONFIGURATION[\"N_STRIDES\"]*2),\n",
        "    Dropout(rate = CONFIGURATION[\"DROPOUT_RATE\"] ),\n",
        "\n",
        "    Conv2D(filters = CONFIGURATION[\"N_FILTERS\"]*2 + 4, kernel_size = CONFIGURATION[\"KERNEL_SIZE\"], strides=CONFIGURATION[\"N_STRIDES\"], padding='valid',\n",
        "          activation = 'relu', kernel_regularizer = L2(CONFIGURATION[\"REGULARIZATION_RATE\"])),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D (pool_size = CONFIGURATION[\"POOL_SIZE\"], strides= CONFIGURATION[\"N_STRIDES\"]*2),\n",
        "\n",
        "    Conv2D(filters = CONFIGURATION[\"N_FILTERS\"]*4 + 8, kernel_size = CONFIGURATION[\"KERNEL_SIZE\"], strides=CONFIGURATION[\"N_STRIDES\"], padding='valid',\n",
        "      activation = 'relu', kernel_regularizer = L2(CONFIGURATION[\"REGULARIZATION_RATE\"])),\n",
        "      BatchNormalization(),\n",
        "    MaxPool2D (pool_size = CONFIGURATION[\"POOL_SIZE\"], strides= CONFIGURATION[\"N_STRIDES\"]*2),\n",
        "    Dropout(rate = CONFIGURATION[\"DROPOUT_RATE\"] ),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    Dense( CONFIGURATION[\"N_DENSE_1\"], activation = \"relu\", kernel_regularizer = L2(CONFIGURATION[\"REGULARIZATION_RATE\"])),\n",
        "    BatchNormalization(),\n",
        "    Dropout(rate = CONFIGURATION[\"DROPOUT_RATE\"]),\n",
        "\n",
        "    Dense( CONFIGURATION['N_DENSE_2'], activation = \"relu\", kernel_regularizer = L2(CONFIGURATION[\"REGULARIZATION_RATE\"])),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Dense(CONFIGURATION[\"NUM_CLASSES\"], activation = \"softmax\"),\n",
        "\n",
        "])\n",
        "\n",
        "lenet_model.summary()"
      ],
      "metadata": {
        "id": "ar-foWumvh6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>TRAINING</h1>"
      ],
      "metadata": {
        "id": "NI1dOPEH2o_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = CategoricalCrossentropy()\n",
        "# loss_function = CrossCategoricalCrossentropy()"
      ],
      "metadata": {
        "id": "6vT9R9jAyLhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = [CategoricalAccuracy(name = \"accuracy\"), TopKCategoricalAccuracy(k = 2, name = \"top_k_accuracy\")]"
      ],
      "metadata": {
        "id": "o3FRi15p409n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.compile(\n",
        "    optimizer = Adam(learning_rate=CONFIGURATION[\"LEARNING_RATE\"]),\n",
        "    loss = loss_function,\n",
        "    metrics = metrics\n",
        ")"
      ],
      "metadata": {
        "id": "H1GMuEHu6FvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = EarlyStopping(\n",
        "    monitor=\"accuracy\",\n",
        "    min_delta=0.00001,\n",
        "    patience=20,\n",
        "    verbose=1,\n",
        "    mode=\"auto\",\n",
        "    baseline=None,\n",
        "    restore_best_weights=False\n",
        ")"
      ],
      "metadata": {
        "id": "Bj55KCUE4Itu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = lenet_model.fit(\n",
        "    training_dataset,\n",
        "    validation_data = validation_dataset,\n",
        "    epochs = CONFIGURATION[\"N_EPOCHS\"],\n",
        "    verbose = True,\n",
        "    callbacks = callback\n",
        ")"
      ],
      "metadata": {
        "id": "9N3mjks_6dqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_loss', 'val_loss'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3HigCm4aDlfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_accuracy', 'val_accuracy'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "riHD4ON-OEVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Evaluation</h1>"
      ],
      "metadata": {
        "id": "Yrs0AJSIBg0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.evaluate(validation_dataset)"
      ],
      "metadata": {
        "id": "noK66Ay6OtWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Testing</h1>"
      ],
      "metadata": {
        "id": "VdA87EzHB38t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = cv2.imread(\"/content/dataset/Emotions Dataset/Emotions Dataset/test/happy/110020.jpg\")\n",
        "test_im = tf.constant(test_image, dtype = tf.float32)\n",
        "\n",
        "test_im = tf.expand_dims(test_im, axis = 0)\n",
        "print(CLASS_NAMES[tf.argmax(lenet_model(test_im), axis = -1 ).numpy()[0]])"
      ],
      "metadata": {
        "id": "zee7ewE4BwSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = cv2.imread(\"/content/dataset/Emotions Dataset/Emotions Dataset/test/angry/104324.jpg_rotation_2.jpg\")\n",
        "test_im = tf.constant(test_image, dtype = tf.float32)\n",
        "\n",
        "test_im = tf.expand_dims(test_im, axis = 0)\n",
        "print(CLASS_NAMES[tf.argmax(lenet_model(test_im), axis = -1 ).numpy()[0]])"
      ],
      "metadata": {
        "id": "xV5wfBCYHh1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = cv2.imread(\"/content/dataset/Emotions Dataset/Emotions Dataset/test/sad/104956.jpg_brightness_2.jpg\")\n",
        "test_im = tf.constant(test_image, dtype = tf.float32)\n",
        "\n",
        "test_im = tf.expand_dims(test_im, axis = 0)\n",
        "print(CLASS_NAMES[tf.argmax(lenet_model(test_im), axis = -1 ).numpy()[0]])"
      ],
      "metadata": {
        "id": "s96c-KioH4Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (14,8))\n",
        "\n",
        "for images, labels in validation_dataset.take(1):\n",
        "  for i in range(5):\n",
        "    ax = plt.subplot(5,5, i+1)\n",
        "    plt.imshow(images[i]/255.)\n",
        "    plt.title(\"true Label :\" + CLASS_NAMES[tf.argmax(labels[i], axis = 0).numpy()] + \"\\n\" + \"Predictedd Label :\" + CLASS_NAMES[tf.argmax(lenet_model(tf.expand_dims(images[i], axis = 0)), axis = -1 ).numpy()[0]])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "fsS8kI1tIEAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Confusion Matrix</h1>"
      ],
      "metadata": {
        "id": "0EEaqJ1CMXfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = []\n",
        "labels = []\n",
        "\n",
        "for test_im , label in val_dataset :\n",
        "  predicted.append(lenet_model(test_im))\n",
        "  labels.append(label.numpy())"
      ],
      "metadata": {
        "id": "qDwLUhdhJVZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.argmax(labels[:-1], axis = -1).flatten())\n",
        "print(np.argmax(predicted[:-1], axis = -1).flatten())"
      ],
      "metadata": {
        "id": "mHyOKDPUM6Gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = np.argmax(predicted[:-1], axis = -1).flatten()\n",
        "lab = np.argmax(labels[:-1], axis = -1).flatten()"
      ],
      "metadata": {
        "id": "MsYp0V6SNPm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(lab, pred)\n",
        "print(cm)\n",
        "\n",
        "plt.figure(figsize = (8,8))\n",
        "\n",
        "sns.heatmap(cm, annot = True,)\n",
        "plt.title('Confusion Matrix - {}'.format(cm))\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')"
      ],
      "metadata": {
        "id": "8s4pT45UO89N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Live Emotion Detection Through Camera</h1>"
      ],
      "metadata": {
        "id": "uc1YHd3ExaDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "iUB54HNGxkhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define the configuration variable\n",
        "CONFIGURATION = {\"IM_SIZE\": 64}\n",
        "\n",
        "def detect_emotion_from_camera():\n",
        "    # Load the trained model\n",
        "    model = lenet_model\n",
        "\n",
        "    # Load the class names\n",
        "    class_names = CLASS_NAMES\n",
        "\n",
        "    # Initialize the camera\n",
        "    cap = cv2.VideoCapture(0)\n",
        "\n",
        "    while True:\n",
        "        # Capture a frame from the camera\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        # Resize the frame to the input size of the model\n",
        "        frame = cv2.resize(frame, (CONFIGURATION[\"IM_SIZE\"], CONFIGURATION[\"IM_SIZE\"]))\n",
        "\n",
        "        # Convert the frame to a tensor\n",
        "        frame_tensor = tf.convert_to_tensor(frame)\n",
        "\n",
        "        # Normalize the pixel values\n",
        "        frame_tensor = frame_tensor / 255.0\n",
        "\n",
        "        # Add a batch dimension\n",
        "        frame_tensor = tf.expand_dims(frame_tensor, axis=0)\n",
        "\n",
        "        # Make a prediction\n",
        "        predictions = model.predict(frame_tensor)\n",
        "\n",
        "        # Get the predicted class\n",
        "        predicted_class = tf.argmax(predictions, axis=-1).numpy()\n",
        "\n",
        "        # Get the corresponding class name\n",
        "        class_name = class_names[predicted_class[0]]\n",
        "\n",
        "        # Display the predicted emotion on the frame\n",
        "        cv2.putText(frame, class_name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "        # Display the frame\n",
        "        cv2.imshow('Emotion Detection', frame)\n",
        "\n",
        "        # Exit if the"
      ],
      "metadata": {
        "id": "nPmJ-5f3xna2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    detect_emotion_from_camera()"
      ],
      "metadata": {
        "id": "-T3QVDkJ1KzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LgeoIb1f9O5M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}